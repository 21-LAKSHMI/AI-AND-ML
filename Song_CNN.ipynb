{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d27f597e-a711-4d13-b42d-35e1a4bfb6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0c0b0dc-071d-4029-8eb1-d12ab96f7930",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = r\"C:\\Users\\USER\\Desktop\\Song_dataset\"\n",
    "SR = 22050 # sample rate\n",
    "DURATION = 30.0 # seconds per clip (you chose 30s)\n",
    "N_MELS = 128\n",
    "N_FFT = 2048\n",
    "HOP_LENGTH = 512\n",
    "MAX_PAD_LEN = int(np.ceil((DURATION * SR) / HOP_LENGTH))\n",
    "FEATURES_FILE = 'X.npy'\n",
    "LABELS_FILE = 'y.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5585619b-ef56-4f29-a204-7b6a98acd9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mel_spectrogram(file_path, sr=SR, duration=DURATION, n_mels=N_MELS, n_fft=N_FFT, hop_length=HOP_LENGTH, max_pad_len=MAX_PAD_LEN):\n",
    "    try:\n",
    "        audio, sr = librosa.load(file_path, sr=sr, duration=duration, res_type='kaiser_fast')\n",
    "        mel_spec = librosa.feature.melspectrogram(y=audio, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)\n",
    "        mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "\n",
    "\n",
    "# pad or truncate\n",
    "        if mel_spec_db.shape[1] < max_pad_len:\n",
    "           pad_width = max_pad_len - mel_spec_db.shape[1]\n",
    "           mel_spec_db = np.pad(mel_spec_db, pad_width=((0,0),(0,pad_width)), mode='constant')\n",
    "        else:\n",
    "           mel_spec_db = mel_spec_db[:, :max_pad_len]\n",
    "\n",
    "\n",
    "        return mel_spec_db\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21ebdc2e-89b3-40f7-8ec3-c83c13ce2ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from audio files. This may take a while...\n",
      "Found genres: ['melody', 'rap']\n",
      "Processing 20 files in genre 'melody'\n",
      "Processing 21 files in genre 'rap'\n",
      "Saved features to X.npy and labels to y.npy\n",
      "Feature array shape: (41, 128, 1292)\n",
      "Labels shape: (41,)\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(FEATURES_FILE) and os.path.exists(LABELS_FILE):\n",
    "    print(\"Loading saved features...\")\n",
    "    X = np.load(FEATURES_FILE)\n",
    "    y = np.load(LABELS_FILE)\n",
    "else:\n",
    "    print(\"Extracting features from audio files. This may take a while...\")\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "\n",
    "    genres = [d for d in os.listdir(DATASET_PATH) if os.path.isdir(os.path.join(DATASET_PATH, d))]\n",
    "    print(f\"Found genres: {genres}\")\n",
    "\n",
    "\n",
    "    for genre in genres:\n",
    "        genre_path = os.path.join(DATASET_PATH, genre)\n",
    "        files = [f for f in os.listdir(genre_path) if f.lower().endswith(('.mp3', '.wav', '.flac', '.ogg'))]\n",
    "        print(f\"Processing {len(files)} files in genre '{genre}'\")\n",
    "\n",
    "\n",
    "        for file in files:\n",
    "            file_path = os.path.join(genre_path, file)\n",
    "            mel = extract_mel_spectrogram(file_path)\n",
    "            if mel is not None:\n",
    "                X.append(mel)\n",
    "                y.append(genre)\n",
    "\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "\n",
    "    # Save for faster reuse\n",
    "    np.save(FEATURES_FILE, X)\n",
    "    np.save(LABELS_FILE, y)\n",
    "    print(f\"Saved features to {FEATURES_FILE} and labels to {LABELS_FILE}\")\n",
    "\n",
    "\n",
    "print(\"Feature array shape:\", X.shape)\n",
    "print(\"Labels shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "226a527a-e155-4745-bcfa-67ef8b24aa44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (32, 128, 1292, 1) Test shape: (9, 128, 1292, 1)\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "y_onehot = to_categorical(y_encoded)\n",
    "# Add channel dimension for CNN: (samples, n_mels, time_steps, 1)\n",
    "X = X[..., np.newaxis]\n",
    "\n",
    "\n",
    "# Normalize X to range 0-1\n",
    "X_min = X.min()\n",
    "X_max = X.max()\n",
    "X = (X - X_min) / (X_max - X_min + 1e-9)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_onehot, test_size=0.2, random_state=42, stratify=y_onehot)\n",
    "\n",
    "\n",
    "print(\"Train shape:\", X_train.shape, \"Test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e72fe386-9470-497f-b6ff-82d9b2a75be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 128, 1292, 32)     320       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 128, 1292, 32)    128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 64, 646, 32)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64, 646, 32)       0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 64, 646, 64)       18496     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 64, 646, 64)      256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 32, 323, 64)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32, 323, 64)       0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 32, 323, 128)      73856     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 32, 323, 128)     512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 16, 161, 128)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 16, 161, 128)      0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 329728)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               84410624  \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 514       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 84,504,706\n",
      "Trainable params: 84,504,258\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = X_train.shape[1:]\n",
    "num_classes = y_onehot.shape[1]\n",
    "\n",
    "\n",
    "def build_model(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "\n",
    "\n",
    "    model.add(Conv2D(32, (3,3), activation='relu', padding='same', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2,2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "    model.add(Conv2D(64, (3,3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2,2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "    model.add(Conv2D(128, (3,3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2,2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_model(input_shape, num_classes)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9319bec-0832-4c0c-b2d5-b0a07a67c683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "2/2 [==============================] - 27s 10s/step - loss: 92.8010 - accuracy: 0.4800 - val_loss: 2.1093 - val_accuracy: 0.4286 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "2/2 [==============================] - 17s 9s/step - loss: 414.6501 - accuracy: 0.5200 - val_loss: 4.6313 - val_accuracy: 0.5714 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "2/2 [==============================] - 11s 4s/step - loss: 55.5095 - accuracy: 0.7600 - val_loss: 12.6093 - val_accuracy: 0.5714 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 118.0895 - accuracy: 0.6400\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2/2 [==============================] - 12s 5s/step - loss: 118.0895 - accuracy: 0.6400 - val_loss: 19.3959 - val_accuracy: 0.5714 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "2/2 [==============================] - 13s 5s/step - loss: 32.7797 - accuracy: 0.8400 - val_loss: 23.7984 - val_accuracy: 0.5714 - lr: 5.0000e-04\n",
      "Epoch 6/30\n",
      "2/2 [==============================] - 18s 11s/step - loss: 27.1495 - accuracy: 0.8400 - val_loss: 27.0170 - val_accuracy: 0.5714 - lr: 5.0000e-04\n",
      "Epoch 7/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 42.3401 - accuracy: 0.7600 \n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "2/2 [==============================] - 34s 8s/step - loss: 42.3401 - accuracy: 0.7600 - val_loss: 30.7774 - val_accuracy: 0.5714 - lr: 5.0000e-04\n",
      "Epoch 8/30\n",
      "2/2 [==============================] - 14s 6s/step - loss: 6.2021 - accuracy: 0.8800 - val_loss: 36.5654 - val_accuracy: 0.5714 - lr: 2.5000e-04\n",
      "Epoch 9/30\n",
      "2/2 [==============================] - 12s 5s/step - loss: 11.7520 - accuracy: 0.8000 - val_loss: 43.1756 - val_accuracy: 0.5714 - lr: 2.5000e-04\n",
      "Epoch 10/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0550 - accuracy: 0.9200\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "2/2 [==============================] - 13s 6s/step - loss: 2.0550 - accuracy: 0.9200 - val_loss: 49.6035 - val_accuracy: 0.5714 - lr: 2.5000e-04\n",
      "Epoch 11/30\n",
      "2/2 [==============================] - 13s 4s/step - loss: 10.5780 - accuracy: 0.8400 - val_loss: 55.1146 - val_accuracy: 0.5714 - lr: 1.2500e-04\n",
      "Epoch 12/30\n",
      "2/2 [==============================] - 10s 4s/step - loss: 4.2489 - accuracy: 0.9200 - val_loss: 60.3327 - val_accuracy: 0.5714 - lr: 1.2500e-04\n",
      "Epoch 13/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 3.0453 - accuracy: 0.8800\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "2/2 [==============================] - 10s 4s/step - loss: 3.0453 - accuracy: 0.8800 - val_loss: 65.7013 - val_accuracy: 0.5714 - lr: 1.2500e-04\n",
      "Epoch 14/30\n",
      "2/2 [==============================] - 12s 6s/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 70.4151 - val_accuracy: 0.5714 - lr: 6.2500e-05\n",
      "Epoch 15/30\n",
      "2/2 [==============================] - 12s 5s/step - loss: 6.1971 - accuracy: 0.8800 - val_loss: 74.8584 - val_accuracy: 0.5714 - lr: 6.2500e-05\n",
      "Epoch 16/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 6.4441 - accuracy: 0.9200\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "2/2 [==============================] - 13s 5s/step - loss: 6.4441 - accuracy: 0.9200 - val_loss: 78.7017 - val_accuracy: 0.5714 - lr: 6.2500e-05\n",
      "Epoch 17/30\n",
      "2/2 [==============================] - 10s 4s/step - loss: 8.6763 - accuracy: 0.8800 - val_loss: 82.3010 - val_accuracy: 0.5714 - lr: 3.1250e-05\n",
      "Epoch 18/30\n",
      "2/2 [==============================] - 14s 5s/step - loss: 4.9655 - accuracy: 0.9200 - val_loss: 85.6586 - val_accuracy: 0.5714 - lr: 3.1250e-05\n",
      "Epoch 19/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.8750 - accuracy: 0.9200\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "2/2 [==============================] - 11s 4s/step - loss: 1.8750 - accuracy: 0.9200 - val_loss: 89.0879 - val_accuracy: 0.5714 - lr: 3.1250e-05\n",
      "Epoch 20/30\n",
      "2/2 [==============================] - 10s 4s/step - loss: 2.8696 - accuracy: 0.8800 - val_loss: 92.1650 - val_accuracy: 0.5714 - lr: 1.5625e-05\n",
      "Epoch 21/30\n",
      "2/2 [==============================] - 10s 4s/step - loss: 0.3910 - accuracy: 0.9600 - val_loss: 95.0990 - val_accuracy: 0.5714 - lr: 1.5625e-05\n",
      "Epoch 22/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0098 - accuracy: 1.0000\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "2/2 [==============================] - 11s 4s/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 97.7314 - val_accuracy: 0.5714 - lr: 1.5625e-05\n",
      "Epoch 23/30\n",
      "2/2 [==============================] - 10s 4s/step - loss: 1.2909 - accuracy: 0.9600 - val_loss: 100.2661 - val_accuracy: 0.5714 - lr: 7.8125e-06\n",
      "Epoch 24/30\n",
      "2/2 [==============================] - 9s 4s/step - loss: 2.3073 - accuracy: 0.9200 - val_loss: 102.6108 - val_accuracy: 0.5714 - lr: 7.8125e-06\n",
      "Epoch 25/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0695 - accuracy: 0.9600    \n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "2/2 [==============================] - 15s 7s/step - loss: 0.0695 - accuracy: 0.9600 - val_loss: 104.9519 - val_accuracy: 0.5714 - lr: 7.8125e-06\n",
      "Epoch 26/30\n",
      "2/2 [==============================] - 14s 4s/step - loss: 3.8147e-08 - accuracy: 1.0000 - val_loss: 107.0090 - val_accuracy: 0.5714 - lr: 3.9063e-06\n",
      "Epoch 27/30\n",
      "2/2 [==============================] - 11s 4s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 109.1342 - val_accuracy: 0.5714 - lr: 3.9063e-06\n",
      "Epoch 28/30\n",
      "2/2 [==============================] - ETA: 0s - loss: 4.8510 - accuracy: 0.9200    \n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "2/2 [==============================] - 11s 4s/step - loss: 4.8510 - accuracy: 0.9200 - val_loss: 110.9641 - val_accuracy: 0.5714 - lr: 3.9063e-06\n",
      "Epoch 29/30\n",
      "2/2 [==============================] - 15s 6s/step - loss: 1.9729 - accuracy: 0.9600 - val_loss: 112.5772 - val_accuracy: 0.5714 - lr: 1.9531e-06\n",
      "Epoch 30/30\n",
      "2/2 [==============================] - 12s 4s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 114.1323 - val_accuracy: 0.5714 - lr: 1.9531e-06\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True, mode='max')\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n",
    "\n",
    "\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "X_train, y_train,\n",
    "validation_split=0.2,\n",
    "epochs=EPOCHS,\n",
    "batch_size=BATCH_SIZE,\n",
    "callbacks=[checkpoint, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000d0a82-a6f9-4a0b-a82f-7161e5cee493",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (LakshmiDL)",
   "language": "python",
   "name": "lakshmidl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
