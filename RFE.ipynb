{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOiClr8q/pqvKV59vkbwff2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/21-LAKSHMI/AI-AND-ML/blob/main/RFE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-Ptd6oK9CXbw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.feature_selection import RFE\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the preprocessed CSV file\n",
        "dataset = pd.read_csv('/content/Iris.csv')\n",
        "\n",
        "# Inspect the DataFrame\n",
        "print(dataset.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DN72vEgCDhyV",
        "outputId": "152e846b-6098-4ac9-aeb3-59d10c54d380"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
            "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
            "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
            "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
            "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
            "4   5            5.0           3.6            1.4           0.2  Iris-setosa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oN4uGPfDmqo",
        "outputId": "b0808231-c82c-4929-dbac-f75b8f10dab6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Id', 'SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm',\n",
              "       'Species'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indep_X=dataset[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']]"
      ],
      "metadata": {
        "id": "V_e9SYmeEBCN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dep_Y=dataset[['Species']]"
      ],
      "metadata": {
        "id": "wR81moy9EN6V"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_scalar(indep_X,dep_Y):\n",
        "        X_train, X_test, y_train, y_test = train_test_split(indep_X, dep_Y, test_size = 0.25, random_state = 0)\n",
        "\n",
        "        sc = StandardScaler()\n",
        "        X_train = sc.fit_transform(X_train)\n",
        "        X_test = sc.transform(X_test)\n",
        "        return X_train, X_test, y_train, y_test"
      ],
      "metadata": {
        "id": "q58IjGBxGJ_r"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_prediction(classifier, X_test, y_test):\n",
        "    y_pred = classifier.predict(X_test)\n",
        "    from sklearn.metrics import accuracy_score\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "sNSj-BaSEVps"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Logistic(X_train, y_train, X_test, y_test):\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "    classifier = LogisticRegression(random_state = 0)\n",
        "    classifier.fit(X_train, y_train)\n",
        "    accuracy = accuracy_prediction(classifier, X_test, y_test)\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "ve8WCaaSFWQu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Random_Forest_Classifier(X_train, y_train, X_test, y_test):\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "    classifier = RandomForestClassifier(n_estimators=100, random_state=0)\n",
        "    classifier.fit(X_train, y_train)\n",
        "    accuracy = accuracy_prediction(classifier, X_test, y_test)\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "JjedbUJULdRb"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def KNN_Classifier(X_train, y_train, X_test, y_test):\n",
        "    from sklearn.neighbors import KNeighborsClassifier\n",
        "    # You might want to tune the number of neighbors (n_neighbors)\n",
        "    classifier = KNeighborsClassifier(n_neighbors=5)\n",
        "    classifier.fit(X_train, y_train)\n",
        "    accuracy = accuracy_prediction(classifier, X_test, y_test)\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "L19LLubmLl4z"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def SVM_Classifier(X_train, y_train, X_test, y_test):\n",
        "    from sklearn.svm import SVC\n",
        "    # You might want to tune the kernel and other parameters\n",
        "    classifier = SVC(kernel='linear', random_state=0)\n",
        "    classifier.fit(X_train, y_train)\n",
        "    accuracy = accuracy_prediction(classifier, X_test, y_test)\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "yosd76uaLvp0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19ef9de2"
      },
      "source": [
        "def DecisionTree(X_train, y_train, X_test, y_test):\n",
        "    from sklearn.tree import DecisionTreeClassifier\n",
        "    classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
        "    classifier.fit(X_train, y_train)\n",
        "    accuracy = accuracy_prediction(classifier, X_test, y_test)\n",
        "    return accuracy"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rfeFeature_classification(indep_X, dep_Y, n):\n",
        "    rfelist = []\n",
        "    colnames_list = []\n",
        "    accuracy_values = []\n",
        "\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "    log = LogisticRegression(random_state=0)\n",
        "\n",
        "    from sklearn.tree import DecisionTreeClassifier\n",
        "    dec = DecisionTreeClassifier(random_state=0)\n",
        "\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "    rf = RandomForestClassifier(n_estimators=10, random_state=0)\n",
        "\n",
        "    from sklearn.svm import SVC\n",
        "    svm = SVC(kernel='linear', random_state=0)\n",
        "\n",
        "    from sklearn.neighbors import KNeighborsClassifier\n",
        "    knn = KNeighborsClassifier(n_neighbors=2)\n",
        "\n",
        "    # Added KNN back, but note that RFE with KNN might not work as expected\n",
        "    # as KNN does not have coef_ or feature_importances_ attributes\n",
        "    rfemodellist = [log, dec, rf, svm, knn]\n",
        "\n",
        "    # Numerically encode the target variable before the loop\n",
        "    from sklearn.preprocessing import LabelEncoder\n",
        "    le = LabelEncoder()\n",
        "    dep_Y_encoded = le.fit_transform(dep_Y.values.ravel())\n",
        "    # Convert the encoded target variable back to a DataFrame with a column name\n",
        "    dep_Y_encoded_df = pd.DataFrame(dep_Y_encoded, columns=['Species_Encoded'])\n",
        "\n",
        "\n",
        "    for model in rfemodellist:\n",
        "        # Ensure n_features_to_select is not greater than the number of features\n",
        "        n_features = indep_X.shape[1]\n",
        "        n_select = min(n, n_features)\n",
        "        if n_select == 0:\n",
        "            n_select = 1 # Ensure at least one feature is selected\n",
        "\n",
        "        # Handle potential issue with RFE and models without feature importances/coefficients\n",
        "        try:\n",
        "            log_rfe = RFE(estimator=model, n_features_to_select=n_select)\n",
        "            # Fit RFE with the original independent variables and the encoded dependent variable\n",
        "            log_fit = log_rfe.fit(indep_X, dep_Y_encoded)\n",
        "            log_rfe_feature = log_fit.transform(indep_X)\n",
        "            selected_columns = [col for col, selected in zip(indep_X.columns, log_rfe.support_) if selected]\n",
        "        except (AttributeError, ValueError) as e:\n",
        "            print(f\"Could not perform RFE with {type(model).__name__}: {e}\")\n",
        "            # If RFE fails, use all features\n",
        "            log_rfe_feature = indep_X.values\n",
        "            selected_columns = indep_X.columns.tolist()\n",
        "\n",
        "\n",
        "        rfelist.append(log_rfe_feature)\n",
        "        colnames_list.append(selected_columns)\n",
        "\n",
        "        # Use split_scalar with the RFE selected features and the encoded dependent variable DataFrame\n",
        "        # Ensure the selected features are in a DataFrame with correct column names for split_scalar\n",
        "        X_train, X_test, y_train, y_test = split_scalar(pd.DataFrame(log_rfe_feature, columns=selected_columns), dep_Y_encoded_df)\n",
        "\n",
        "        # Reshape y_train and y_test to 1D arrays for fitting and evaluation\n",
        "        model.fit(X_train, y_train.values.ravel())\n",
        "        accuracy = accuracy_prediction(model, X_test, y_test.values.ravel())\n",
        "        accuracy_values.append(accuracy)\n",
        "\n",
        "    return rfelist, colnames_list, accuracy_values\n",
        "\n",
        "# Example usage (assuming you have classification data in indep_X and dep_Y)\n",
        "rfelist, colnames_list, accuracy_values = rfeFeature_classification(indep_X, dep_Y, 2)\n",
        "\n",
        "# Print the selected column names and accuracy values for each model\n",
        "# Ensure model names list matches the rfemodellist\n",
        "for model_name, selected_columns, accuracy_value in zip([\"Logistic\", \"Decision\", \"Random\", \"SVM\", \"KNN\"], colnames_list, accuracy_values):\n",
        "     print(f\"Model: {model_name}\")\n",
        "     print(\"Selected Columns:\", selected_columns)\n",
        "     print(f\"Accuracy Value: {accuracy_value}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPZ7HVmDIt2q",
        "outputId": "58f4b7d8-c7ae-48f2-fdaf-b08c84bf1225"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not perform RFE with KNeighborsClassifier: when `importance_getter=='auto'`, the underlying estimator KNeighborsClassifier should have `coef_` or `feature_importances_` attribute. Either pass a fitted estimator to feature selector or call fit before calling transform.\n",
            "Model: Logistic\n",
            "Selected Columns: ['PetalLengthCm', 'PetalWidthCm']\n",
            "Accuracy Value: 0.9473684210526315\n",
            "\n",
            "Model: Decision\n",
            "Selected Columns: ['PetalLengthCm', 'PetalWidthCm']\n",
            "Accuracy Value: 0.9473684210526315\n",
            "\n",
            "Model: Random\n",
            "Selected Columns: ['PetalLengthCm', 'PetalWidthCm']\n",
            "Accuracy Value: 0.9736842105263158\n",
            "\n",
            "Model: SVM\n",
            "Selected Columns: ['PetalLengthCm', 'PetalWidthCm']\n",
            "Accuracy Value: 0.9736842105263158\n",
            "\n",
            "Model: KNN\n",
            "Selected Columns: ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']\n",
            "Accuracy Value: 0.9473684210526315\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have classification data in indep_X_cls and dep_Y_cls\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(indep_X, dep_Y, test_size=0.30, random_state=0)\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "classifier_dt = DecisionTreeClassifier(criterion='gini', splitter='best', random_state=0) # Common criteria are 'gini' or 'entropy'\n",
        "classifier_dt.fit(X_train, y_train)\n",
        "\n",
        "# # To evaluate the model using the accuracy_prediction function\n",
        "accuracy_dt = accuracy_prediction(classifier_dt, X_test, y_test)\n",
        "print(f\"Decision Tree Classifier Accuracy: {accuracy_dt}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JyZSkV7LMxp",
        "outputId": "e36c812f-e5bc-450d-8ef4-88f5ac1c1b92"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Classifier Accuracy: 0.9777777777777777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = classifier_dt.predict(X_test)"
      ],
      "metadata": {
        "id": "RA2P4-RQM_5n"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Assuming you have the true labels (y_test_cls) and predicted labels (y_pred_cls) for your classification task\n",
        "\n",
        "# Calculate Precision\n",
        "precision = precision_score(y_test, y_pred, average='weighted') # Use 'weighted' for multiclass or if you have class imbalance\n",
        "print(f\"Precision: {precision}\")\n",
        "\n",
        "# Calculate Recall\n",
        "recall = recall_score(y_test, y_pred, average='weighted') # Use 'weighted' for multiclass or if you have class imbalance\n",
        "print(f\"Recall: {recall}\")\n",
        "\n",
        "# Calculate F1-score\n",
        "f1 = f1_score(y_test, y_pred, average='weighted') # Use 'weighted' for multiclass or if you have class imbalance\n",
        "print(f\"F1-score: {f1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eVoqg98NT6-",
        "outputId": "6faa6980-004c-4c6c-dd9c-2bee193f3fe6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.9796296296296295\n",
            "Recall: 0.9777777777777777\n",
            "F1-score: 0.9779434092477569\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have classification data in indep_X_cls and dep_Y_cls\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(indep_X, dep_Y, test_size=0.30, random_state=0)\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier_dt = RandomForestClassifier(criterion='gini', random_state=0) # Removed splitter='best' as it's not a valid parameter for RandomForestClassifier\n",
        "classifier_dt.fit(X_train, y_train)\n",
        "\n",
        "# # To evaluate the model using the accuracy_prediction function\n",
        "accuracy_dt = accuracy_prediction(classifier_dt, X_test, y_test)\n",
        "print(f\"Random Forest Classifier Accuracy: {accuracy_dt}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bOguo7oOTs4",
        "outputId": "8405f648-c975-492c-aaba-efc8efc57faf"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return fit_method(estimator, *args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Classifier Accuracy: 0.9777777777777777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = classifier_dt.predict(X_test)"
      ],
      "metadata": {
        "id": "xD6cF4oVQeBp"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Assuming you have the true labels (y_test_cls) and predicted labels (y_pred_cls) for your classification task\n",
        "\n",
        "# Calculate Precision\n",
        "precision = precision_score(y_test, y_pred, average='weighted') # Use 'weighted' for multiclass or if you have class imbalance\n",
        "print(f\"Precision: {precision}\")\n",
        "\n",
        "# Calculate Recall\n",
        "recall = recall_score(y_test, y_pred, average='weighted') # Use 'weighted' for multiclass or if you have class imbalance\n",
        "print(f\"Recall: {recall}\")\n",
        "\n",
        "# Calculate F1-score\n",
        "f1 = f1_score(y_test, y_pred, average='weighted') # Use 'weighted' for multiclass or if you have class imbalance\n",
        "print(f\"F1-score: {f1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ish78tqmQp4W",
        "outputId": "d1ecb586-5c5f-41c8-dee3-f5ace19f9816"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.9796296296296295\n",
            "Recall: 0.9777777777777777\n",
            "F1-score: 0.9779434092477569\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have classification data in indep_X_cls and dep_Y_cls\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(indep_X, dep_Y, test_size=0.30, random_state=0)\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "classifier_svm = SVC(kernel='linear', random_state=0) # Common kernels are 'linear', 'rbf', 'poly', 'sigmoid'\n",
        "classifier_svm.fit(X_train, y_train)\n",
        "\n",
        "# # To evaluate the model using the accuracy_prediction function\n",
        "accuracy_svm = accuracy_prediction(classifier_svm, X_test, y_test)\n",
        "print(f\"SVM Classifier Accuracy: {accuracy_svm}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqkldCO9Qyaa",
        "outputId": "40074a67-6e3f-489b-ec95-50b8e861b944"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Classifier Accuracy: 0.9777777777777777\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = classifier_dt.predict(X_test)"
      ],
      "metadata": {
        "id": "eiKgc1N0Rh_w"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Assuming you have the true labels (y_test_cls) and predicted labels (y_pred_cls) for your classification task\n",
        "\n",
        "# Calculate Precision\n",
        "precision = precision_score(y_test, y_pred, average='weighted') # Use 'weighted' for multiclass or if you have class imbalance\n",
        "print(f\"Precision: {precision}\")\n",
        "\n",
        "# Calculate Recall\n",
        "recall = recall_score(y_test, y_pred, average='weighted') # Use 'weighted' for multiclass or if you have class imbalance\n",
        "print(f\"Recall: {recall}\")\n",
        "\n",
        "# Calculate F1-score\n",
        "f1 = f1_score(y_test, y_pred, average='weighted') # Use 'weighted' for multiclass or if you have class imbalance\n",
        "print(f\"F1-score: {f1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbbapwSDRtqL",
        "outputId": "2342d93f-3576-4cff-d6a2-36bc3c809b68"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.9796296296296295\n",
            "Recall: 0.9777777777777777\n",
            "F1-score: 0.9779434092477569\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have classification data in indep_X_cls and dep_Y_cls\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(indep_X, dep_Y, test_size=0.30, random_state=0)\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "classifier_knn = KNeighborsClassifier(n_neighbors=5) # Removed kernel='linear' and random_state as they are not valid parameters for KNeighborsClassifier\n",
        "classifier_knn.fit(X_train, y_train)\n",
        "\n",
        "# # To evaluate the model using the accuracy_prediction function\n",
        "accuracy_knn = accuracy_prediction(classifier_knn, X_test, y_test)\n",
        "print(f\"KNN Classifier Accuracy: {accuracy_knn}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASPQChL5RvkE",
        "outputId": "4261dc1d-cce3-43be-8347-88daa204fcb6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Classifier Accuracy: 0.9777777777777777\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/neighbors/_classification.py:239: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = classifier_dt.predict(X_test)"
      ],
      "metadata": {
        "id": "64i2GWdmR77A"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Assuming you have the true labels (y_test_cls) and predicted labels (y_pred_cls) for your classification task\n",
        "\n",
        "# Calculate Precision\n",
        "precision = precision_score(y_test, y_pred, average='weighted') # Use 'weighted' for multiclass or if you have class imbalance\n",
        "print(f\"Precision: {precision}\")\n",
        "\n",
        "# Calculate Recall\n",
        "recall = recall_score(y_test, y_pred, average='weighted') # Use 'weighted' for multiclass or if you have class imbalance\n",
        "print(f\"Recall: {recall}\")\n",
        "\n",
        "# Calculate F1-score\n",
        "f1 = f1_score(y_test, y_pred, average='weighted') # Use 'weighted' for multiclass or if you have class imbalance\n",
        "print(f\"F1-score: {f1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDTUJRAnTWRN",
        "outputId": "525e2e67-3542-4e4f-9b3f-c44eb6d741af"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.9796296296296295\n",
            "Recall: 0.9777777777777777\n",
            "F1-score: 0.9779434092477569\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have classification data in indep_X_cls and dep_Y_cls\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(indep_X, dep_Y, test_size=0.30, random_state=0)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier_lr = LogisticRegression(random_state=0) # Corrected parameters for LogisticRegression\n",
        "classifier_lr.fit(X_train, y_train)\n",
        "\n",
        "# # To evaluate the model using the accuracy_prediction function\n",
        "accuracy_lr = accuracy_prediction(classifier_lr, X_test, y_test)\n",
        "print(f\"Logistic Regression Accuracy: {accuracy_lr}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tfz0AbbKTXlK",
        "outputId": "75efb9f4-b076-4c8d-a170-a64e3b786be6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy: 0.9777777777777777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = classifier_dt.predict(X_test)"
      ],
      "metadata": {
        "id": "Di3Ayu7sUWTW"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Assuming you have the true labels (y_test_cls) and predicted labels (y_pred_cls) for your classification task\n",
        "\n",
        "# Calculate Precision\n",
        "precision = precision_score(y_test, y_pred, average='weighted') # Use 'weighted' for multiclass or if you have class imbalance\n",
        "print(f\"Precision: {precision}\")\n",
        "\n",
        "# Calculate Recall\n",
        "recall = recall_score(y_test, y_pred, average='weighted') # Use 'weighted' for multiclass or if you have class imbalance\n",
        "print(f\"Recall: {recall}\")\n",
        "\n",
        "# Calculate F1-score\n",
        "f1 = f1_score(y_test, y_pred, average='weighted') # Use 'weighted' for multiclass or if you have class imbalance\n",
        "print(f\"F1-score: {f1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFdYGDJoUgsv",
        "outputId": "bc199aaf-5b59-4f65-d91a-a89b14f31cb3"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.9796296296296295\n",
            "Recall: 0.9777777777777777\n",
            "F1-score: 0.9779434092477569\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "Finalised_Model=\"Finalized_model.sav\""
      ],
      "metadata": {
        "id": "l8pSVdXhUjO7"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(classifier_dt,open(Finalised_Model,'wb'))"
      ],
      "metadata": {
        "id": "8KoSkMecVFoB"
      },
      "execution_count": 31,
      "outputs": []
    }
  ]
}